{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('data/x_train.csv')\n",
    "y_train = pd.read_csv('data/y_train.csv')\n",
    "x_val = pd.read_csv('data/x_val.csv')\n",
    "y_val = pd.read_csv('data/y_val.csv')\n",
    "x_test = pd.read_csv('data/x_test.csv')\n",
    "y_test = pd.read_csv('data/y_test.csv')\n",
    "\n",
    "#for splitting after feature extraction\n",
    "# x = x_train.append(x_val).append(x_test)\n",
    "# y = y_train.append(y_val).append(y_test)\n",
    "# x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.1)\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = GaussianNB()\n",
    "SVM = SVC()\n",
    "RF = RandomForestClassifier()\n",
    "AdaBoost = AdaBoostClassifier()\n",
    "KNN = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_chain(model, x_train, y_train, x_test, y_test, num_chian = 10):\n",
    "    if 'utterance' in x_train.columns:\n",
    "        x_train = x_train.drop('utterance', axis=1)\n",
    "        x_test = x_test.drop('utterance', axis=1)\n",
    "        \n",
    "    chains = [ClassifierChain(model, order='random', random_state=i)\n",
    "              for i in range(num_chian)]\n",
    "    for chain in chains:\n",
    "        chain.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = np.array([chain.predict(x_test) for chain in\n",
    "                              chains]).mean(axis=0)\n",
    "    \n",
    "    acc = np.mean(np.sum(np.logical_and((y_pred>0.5), y_test), axis = 1)/np.sum(np.logical_or((y_pred>0.5), y_test), axis = 1))\n",
    "    precision = np.mean(np.sum(np.logical_and((y_pred>0.5), y_test), axis = 1)/np.sum((y_pred>0.5), axis = 1))\n",
    "    recall = np.mean(np.sum(np.logical_and((y_pred>0.5), y_test), axis = 1)/np.sum(y_test, axis = 1))\n",
    "    F1 = 2*(precision*recall)/(precision+recall)\n",
    "    \n",
    "    print('Accuracy:', acc)\n",
    "    print('Precision:', precision)\n",
    "    print('Recall:', recall)\n",
    "    print('F1 score:', F1)\n",
    "    return acc, precision, recall, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3782589262589262\n",
      "Precision: 0.490134987049213\n",
      "Recall: 0.6117106227106228\n",
      "F1 score: 0.5442155878907348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3782589262589262, 0.490134987049213, 0.6117106227106228, 0.5442155878907348)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_chain(NB, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3639206349206349\n",
      "Precision: 0.7408759124087592\n",
      "Recall: 0.3808437118437118\n",
      "F1 score: 0.50308103094012\n",
      "Wall time: 14min 34s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3639206349206349, 0.7408759124087592, 0.3808437118437118, 0.50308103094012)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "classifier_chain(SVM, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5594468864468863\n",
      "Precision: 0.8584188521474724\n",
      "Recall: 0.5836593406593406\n",
      "F1 score: 0.6948640978735902\n",
      "Wall time: 27.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5594468864468863,\n",
       " 0.8584188521474724,\n",
       " 0.5836593406593406,\n",
       " 0.6948640978735902)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "classifier_chain(RF, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5746105006105006\n",
      "Precision: 0.8217866093805943\n",
      "Recall: 0.6121001221001221\n",
      "F1 score: 0.701611463302493\n",
      "Wall time: 2min 43s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5746105006105006, 0.8217866093805943, 0.6121001221001221, 0.701611463302493)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "classifier_chain(AdaBoost, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.36642979242979246\n",
      "Precision: 0.6123232323232323\n",
      "Recall: 0.40529914529914524\n",
      "F1 score: 0.4877528013628434\n"
     ]
    }
   ],
   "source": [
    "KNN.fit(x_train.drop('utterance', axis=1), y_train)\n",
    "y_pred = KNN.predict(x_test.drop('utterance', axis=1))\n",
    "\n",
    "acc = np.mean(np.sum(np.logical_and((y_pred>0.5), y_test), axis = 1)/np.sum(np.logical_or((y_pred>0.5), y_test), axis = 1))\n",
    "precision = np.mean(np.sum(np.logical_and((y_pred>0.5), y_test), axis = 1)/np.sum((y_pred>0.5), axis = 1))\n",
    "recall = np.mean(np.sum(np.logical_and((y_pred>0.5), y_test), axis = 1)/np.sum(y_test, axis = 1))\n",
    "F1 = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "print('Accuracy:', acc)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 score:', F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypeparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(max_depth=depth, min_samples_split= 5, min_samples_leaf=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Con = ['InitSim','DlgSim', 'QuestMark', 'Dup', 'What', 'Where', 'When', 'Why', 'Who', 'How']\n",
    "Str = ['AbsPos', 'NormPos', 'Len', 'LenUni', 'LenStem', 'Starter']\n",
    "Sen = ['Thank', 'ExMark', 'Feedback', 'SenScr_Neg', 'SenScr_Neu', 'SenScr_Pos', 'Lex_Pos', 'Lex_Neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "table6 = pd.DataFrame(columns=['Group(s)','Acc', 'Precision', 'Recall', 'F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4052405372405373\n",
      "Precision: 0.656399845320959\n",
      "Recall: 0.45146764346764345\n",
      "F1 score: 0.5349796692086624\n",
      "Accuracy: 0.49395937395937395\n",
      "Precision: 0.7441099962839094\n",
      "Recall: 0.5320598290598291\n",
      "F1 score: 0.6204676361437829\n",
      "Accuracy: 0.28700122100122105\n",
      "Precision: 0.517053317053317\n",
      "Recall: 0.3157264957264957\n",
      "F1 score: 0.39205424865448124\n",
      "Accuracy: 0.5098632478632479\n",
      "Precision: 0.8032879818594104\n",
      "Recall: 0.5371965811965812\n",
      "F1 score: 0.6438321924236169\n",
      "Accuracy: 0.49606471306471306\n",
      "Precision: 0.7743855606758834\n",
      "Recall: 0.5179157509157509\n",
      "F1 score: 0.6207011871895421\n",
      "Accuracy: 0.5554884004884004\n",
      "Precision: 0.849905303030303\n",
      "Recall: 0.5815054945054945\n",
      "F1 score: 0.6905419525579883\n"
     ]
    }
   ],
   "source": [
    "table6.loc[0] = ['Content'] + list(classifier_chain(RF, x_train[Con], y_train, x_test[Con], y_test))\n",
    "table6.loc[1] = ['Structural'] + list(classifier_chain(RF, x_train[Str], y_train, x_test[Str], y_test))\n",
    "table6.loc[2] = ['Sentiment'] + list(classifier_chain(RF, x_train[Sen], y_train, x_test[Sen], y_test))\n",
    "table6.loc[3] = ['Con+Str'] + list(classifier_chain(RF, x_train[Con+Str], y_train, x_test[Con+Str], y_test))\n",
    "table6.loc[4] = ['Con+Sen'] + list(classifier_chain(RF, x_train[Con+Sen], y_train, x_test[Con+Sen], y_test))\n",
    "table6.loc[5] = ['Str+Sent'] + list(classifier_chain(RF, x_train[Str+Sen], y_train, x_test[Str+Sen], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group(s)</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Content</td>\n",
       "      <td>0.405241</td>\n",
       "      <td>0.656400</td>\n",
       "      <td>0.451468</td>\n",
       "      <td>0.534980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Structural</td>\n",
       "      <td>0.493959</td>\n",
       "      <td>0.744110</td>\n",
       "      <td>0.532060</td>\n",
       "      <td>0.620468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Sentiment</td>\n",
       "      <td>0.287001</td>\n",
       "      <td>0.517053</td>\n",
       "      <td>0.315726</td>\n",
       "      <td>0.392054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Con+Str</td>\n",
       "      <td>0.509863</td>\n",
       "      <td>0.803288</td>\n",
       "      <td>0.537197</td>\n",
       "      <td>0.643832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Con+Sen</td>\n",
       "      <td>0.496065</td>\n",
       "      <td>0.774386</td>\n",
       "      <td>0.517916</td>\n",
       "      <td>0.620701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Str+Sent</td>\n",
       "      <td>0.555488</td>\n",
       "      <td>0.849905</td>\n",
       "      <td>0.581505</td>\n",
       "      <td>0.690542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Group(s)       Acc  Precision    Recall        F1\n",
       "0     Content  0.405241   0.656400  0.451468  0.534980\n",
       "1  Structural  0.493959   0.744110  0.532060  0.620468\n",
       "2   Sentiment  0.287001   0.517053  0.315726  0.392054\n",
       "3     Con+Str  0.509863   0.803288  0.537197  0.643832\n",
       "4     Con+Sen  0.496065   0.774386  0.517916  0.620701\n",
       "5    Str+Sent  0.555488   0.849905  0.581505  0.690542"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-4e58f62a79cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfeature_importances_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    371\u001b[0m             \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         \"\"\"\n\u001b[1;32m--> 373\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimators_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m         all_importances = Parallel(n_jobs=self.n_jobs,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 914\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "print(sorted(zip(map(lambda x: round(x, 4), RF.feature_importances_), names), reverse=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
